apiVersion: apps/v1
kind: Deployment
metadata:
  name: flink-job-runner
  namespace: flink-job-runner
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: flink-job-runner
  template:
    metadata:
      labels:
        app: flink-job-runner
    spec:
      serviceAccountName: flink-job-runner  # Create this ServiceAccount with appropriate permissions
      initContainers:
      - name: setup-work-directory
        image: {{ .Values.mainRepo }}/flink-job-runner:{{ .Values.mainVersion }}
        command:
        - sh
        - -c
        - |
          echo "Setting up work directory structure..."

          # List what's available in the image
          echo "Available directories in /app/work:"
          ls -la /app/work/ || echo "No /app/work directory found"
          echo "Files in /app/work/kms/ from image:"
          ls -la /app/work/kms/ || echo "No kms directory in image"
          echo "Files in /app/work/shacl2flink/ from image:"
          ls -la /app/work/shacl2flink/ || echo "No shacl2flink directory in image"

          # Copy entire work directory structure from image to mounted volume (best effort)
          echo "Copying work directory contents to mounted volume..."
          cp -rv /app/work/* /mounted-work/ 2>&1 || echo "Some files may not exist"

          # Ensure specific directories exist and copy them if needed
          for dir in shacl2flink helm kms; do
            if [ -d "/app/work/$dir" ] && [ ! -d "/mounted-work/$dir" ]; then
              echo "Copying $dir directory to mounted volume..."
              cp -r "/app/work/$dir" "/mounted-work/"
            fi
          done

          # Fix permissions on the mounted volume
          echo "Fixing permissions for /mounted-work..."
          chown -R 1000:1000 /mounted-work
          chmod -R 755 /mounted-work

          # Update compatibility symlinks to point to mounted volume
          echo "Updating compatibility symlinks..."
          
          # Remove existing symlinks (they point to /app/work/* but we need /app/work to be the mounted volume)
          rm -f /app/kms /app/helm /app/shacl2flink || true
          
          # Create new symlinks pointing to the mounted volume paths
          if [ -d "/mounted-work/kms" ]; then
            ln -sf /app/work/kms /app/kms
            echo "Linked /app/kms -> /app/work/kms (mounted volume)"
          fi
          if [ -d "/mounted-work/helm" ]; then
            ln -sf /app/work/helm /app/helm
            echo "Linked /app/helm -> /app/work/helm (mounted volume)"
          fi
          if [ -d "/mounted-work/shacl2flink" ]; then
            ln -sf /app/work/shacl2flink /app/shacl2flink
            echo "Linked /app/shacl2flink -> /app/work/shacl2flink (mounted volume)"
          fi

          # Show final layout
          echo "Final mounted work directory structure:"
          ls -la /mounted-work/ || echo "No mounted work directory"
          echo "Contents of /mounted-work/kms/:"
          ls -la /mounted-work/kms/ || echo "No kms directory in mounted work"
          echo "Contents of /mounted-work/shacl2flink/:"
          ls -la /mounted-work/shacl2flink/ || echo "No shacl2flink directory in mounted work"
          echo "Contents of /mounted-work/helm/:"
          ls -la /mounted-work/helm/ || echo "No helm directory in mounted work"
          echo "Final /app layout (top-level):"
          ls -la /app | sed -n '1,120p' || true
          echo "Testing symlinks:"
          ls -la /app/kms/ || echo "Cannot access /app/kms"
          ls -la /app/helm/ || echo "Cannot access /app/helm"
          ls -la /app/shacl2flink/ || echo "Cannot access /app/shacl2flink"
          echo "Setup complete"
        volumeMounts:
        - name: work-storage
          mountPath: /mounted-work
        securityContext:
          runAsUser: 0  # Run as root to fix permissions
      containers:
      - name: flink-job-runner
        image: {{ .Values.mainRepo }}/flink-job-runner:{{ .Values.mainVersion }}
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
        env:
        - name: RUNNER_BIND
          value: "0.0.0.0"
        - name: RUNNER_PORT
          value: "8080"
        - name: DIGITALTWIN_ROOT
          value: "/app/work/shacl2flink"
        - name: WORK_ROOT
          value: "/app/work"
        # Use the default Kubernetes service account token location
        - name: KUBECONFIG_PATH
          value: "/var/run/secrets/kubernetes.io/serviceaccount"
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        volumeMounts:
        # Optional: mount additional storage for work directory
        - name: work-storage
          mountPath: /app/work
        securityContext:
          runAsUser: 1000  # Run as appuser
          runAsGroup: 1000
          allowPrivilegeEscalation: false
      volumes:
      - name: work-storage
        persistentVolumeClaim:
          claimName: flink-job-runner-pvc-1

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: flink-job-runner-ingress
  namespace: flink-job-runner
  labels:
    app: flink-job-runner
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - dev-flink-job-runner.industryfusion-x.org
    secretName: flink-job-runner-frontend-tls
  rules:
  - host: dev-flink-job-runner.industryfusion-x.org
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: flink-job-runner-service
            port:
              number: 8080


---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: flink-job-runner-pvc-1
  namespace: flink-job-runner
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: ionos-enterprise-hdd
  resources:
    requests:
      storage: 20Gi


---
apiVersion: v1
kind: Service
metadata:
  name: flink-job-runner-service
  namespace: flink-job-runner
spec:
  selector:
    app: flink-job-runner
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 8080
  type: ClusterIP
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flink-job-runner
  namespace: flink-job-runner
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: flink-job-runner
rules:
# Permissions needed for your make targets
- apiGroups: [""]
  resources: ["pods", "services", "endpoints", "secrets"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
- apiGroups: [""]
  resources: ["pods/exec"]
  verbs: ["create"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete", "scale"]
- apiGroups: ["kafka.strimzi.io"]
  resources: ["kafkatopics"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
- apiGroups: ["extensions", "networking.k8s.io"]
  resources: ["ingresses"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
- apiGroups: [""]
  resources: ["namespaces"]
  verbs: ["get", "list", "watch"]
# Add other resources as needed by your Makefile
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: flink-job-runner
subjects:
- kind: ServiceAccount
  name: flink-job-runner
  namespace: flink-job-runner
roleRef:
  kind: ClusterRole
  name: flink-job-runner
  apiGroup: rbac.authorization.k8s.io